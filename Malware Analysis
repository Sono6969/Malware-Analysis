#import pandas as pd
from scapy.all import *
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Function to extract features from a packet
def extract_features(packet):
    ip_header = packet[IP]
    tcp_header = packet[TCP]
    
    return [
        ip_header.src,
        ip_header.dst,
        tcp_header.sport,
        tcp_header.dport,
        ip_header.proto,
        len(packet),
        len(ip_header),
        len(tcp_header)
    ]

# Load PCAP file and extract features
def load_pcap(filename):
    packets = rdpcap(filename)
    features = [extract_features(packet) for packet in packets if IP in packet and TCP in packet]
    return features

# Load dataset from Access table and append online malicious packet data
def load_dataset(db_file, table_name, online_repo):
    conn = pyodbc.connect(r"Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=" + db_file + ";")
    df = pd.read_sql("SELECT * FROM " + table_name, conn)
    conn.close()

    online_data = rdpcap(online_repo + "/packetDataDateMachine.pcap")
    online_df = pd.DataFrame(columns=df.columns)
    for packet in online_data:
        features = extract_features(packet)
        online_df = online_df.append({"src_ip": features[0], "dst_ip": features[1], "src_port": features[2], 
                                      "dst_port": features[3], "protocol": features[4], "packet_length": features[5], 
                                      "ip_header_length": features[6], "tcp_header_length": features[7],
                                      "label": 1}, ignore_index=True)

    df = df.append(online_df, ignore_index=True)
    return df

# Main function for data processing and classification
def main():
    db_file = "C:\\packetDataDB.accdb"
    table_name = "packetData"
    online_repo = "https://www.unb.ca/cic/datasets/ids-2017.html"

    # Load dataset
    df = load_dataset(db_file, table_name, online_repo)

    # Preprocess data
    le = LabelEncoder()
    df["src_ip"] = le.fit_transform(df["src_ip"])
    df["dst_ip"] = le.fit_transform(df["dst_ip"])
    df["protocol"] = le.fit_transform(df["protocol"])

    sc = StandardScaler()
    df[["src_port", "dst_port", "packet_length", "ip_header_length", "tcp_header_length"]] = sc.fit_transform(df[["src_port", "dst_port", "packet_length", "ip_header_length", "tcp_header_length"]])

    # Split data
    X = df[["src_ip", "dst_ip", "src_port", "dst_port", "protocol", "packet_length", "ip_header_length", "tcp_header_length"]]
    y = df["label"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate model
    y_pred = model.predict(X_test)
    score = accuracy_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)
    cr = classification_report(y_test, y_pred)

    print("Accuracy score:", score)
    print("Confusion matrix:\n", cm)
    print("Classification report:\n", cr)

if __name__ == "__main__":
    main()

_____________________________________________________________________________________________________________________

#Preprocess the data from the "MaliciousTrainingData" file and extract the relevant features.
#Train a neural network model using the extracted features and their corresponding labels.
#Preprocess the data from the "Analysis_SystemCallTrace_Date_IP" file in the same way.
#Use the trained neural network model to predict the labels (malicious or benign) for the system 
#calls in the analysis file.

import numpy as np
import pandas as pd
import pyodbc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Function to extract features from system call traces
def extract_features(system_call_trace):
# Implement feature extraction logic here
# Extract features such as system call names, arguments, sequence, frequency, duration, process
# context,
# system call parameters, resource access patterns, error handling, context switches, etc.
# Return the extracted features as a dictionary or list
    
    features = {
        "SystemCallNames": "Example1",  # Replace with actual extracted feature
        "Arguments": "Example2",  # Replace with actual extracted feature
        "SequenceOfSystemCalls": "Example3",  # Replace with actual extracted feature
        "FrequencyOfSystemCalls": "Example4",  # Replace with actual extracted feature
        "DurationOfSystemCalls": "Example5",  # Replace with actual extracted feature
        "ProcessContext": "Example6",  # Replace with actual extracted feature
        "SystemCallParameters": "Example7",  # Replace with actual extracted feature
        "ResourceAccessPatterns": "Example8",  # Replace with actual extracted feature
        "ErrorHandling": "Example9",  # Replace with actual extracted feature
        "ContextSwitches": "Example10"  # Replace with actual extracted feature
    }
    
    return list(features.values())

# Create a new Access database named "SystemCallAnalysis" if it doesn't exist
access_database_path = "SystemCallAnalysis.accdb"
conn_str = r"Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=" + access_database_path
conn = pyodbc.connect(conn_str)

# Create a cursor to execute SQL commands
cursor = conn.cursor()

# Create a table named "SystemCallRaw" in the Access database
cursor.execute('''
    CREATE TABLE IF NOT EXISTS SystemCallRaw (
        ID AUTOINCREMENT PRIMARY KEY,
        SystemCallNames TEXT,
        Arguments TEXT,
        SequenceOfSystemCalls TEXT,
        FrequencyOfSystemCalls INTEGER,
        DurationOfSystemCalls INTEGER,
        ProcessContext TEXT,
        SystemCallParameters TEXT,
        ResourceAccessPatterns TEXT,
        ErrorHandling TEXT,
        ContextSwitches TEXT
    )
''')
conn.commit()

# Extract features from each system call trace and insert into the table
for index, row in system_call_data.iterrows():
    features = extract_features(row)
    cursor.execute('''
        INSERT INTO SystemCallRaw (SystemCallNames, Arguments, SequenceOfSystemCalls, FrequencyOfSystemCalls,
                                   DurationOfSystemCalls, ProcessContext, SystemCallParameters,
                                   ResourceAccessPatterns, ErrorHandling, ContextSwitches)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', tuple(features))

conn.commit()

# Retrieve the entire table as a numpy array
cursor.execute('SELECT * FROM SystemCallRaw')
rows = cursor.fetchall()
table_array = np.array(rows)

# Close the connection
conn.close()

# Return the table array
return table_array

# Load and preprocess malicious system call traces
malicious_data = pd.read_csv("MaliciousTrainingData.csv")  # Adjust filename as needed
X_malicious = extract_features(malicious_data)
y_malicious = malicious_data["label"]  # Labels

# Train a neural network model
model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
model.fit(X_malicious, y_malicious)

# Load and preprocess system call traces for analysis
analysis_data = pd.read_csv("Analysis_SystemCallTrace_Date_IP.csv")  # Adjust filename as needed
X_analysis = extract_features(analysis_data)

# Predict labels for analysis data
predicted_labels = model.predict(X_analysis)

# Flag system calls predicted as malicious
analysis_data["predicted_label"] = predicted_labels
malicious_system_calls = analysis_data[analysis_data["predicted_label"] == 1]

# Output flagged system calls
print("Flagged malicious system calls:")
print(malicious_system_calls)
